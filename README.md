# Web_Scraping-Github-DB-Beautiful_Soup-SQLite

Github topics are parsed, from each topic top repos details are scraped and put into a csv and .xlsx file. This part is done using beautiful soup. The data is also uploaded to database using SQLite. Built from scratch.

To run open a notebook on jupyter notebook and run the file. The data will be saved in the /data/ directory.
